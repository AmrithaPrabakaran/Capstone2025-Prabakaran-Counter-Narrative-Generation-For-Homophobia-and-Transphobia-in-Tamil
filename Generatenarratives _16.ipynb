{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Generating pairs in both gemini and GPT"
      ],
      "metadata": {
        "id": "5aJHDHni8-fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJirJfkf8SpI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCcHuFOoq2ste0srbmOTcQhNCtPwM0FvdM'\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "examples_df = pd.read_excel(\"counter_narrative.xlsx\")\n",
        "input_df = pd.read_excel(\"test.xlsx\").head(100)\n",
        "\n",
        "prompt_prefix = \"\"\n",
        "for _, row in examples_df.iterrows():\n",
        "    prompt_prefix += f\"Toxic: {row['toxic_text']}\\nCounter: {row['counter_narrative']}\\n\\n\"\n",
        "\n",
        "def generate_with_gpt(toxic_text):\n",
        "    prompt = f\"{prompt_prefix}Toxic: {toxic_text}\\nCounter:\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"GPT Error: {e}\"\n",
        "\n",
        "def generate_with_gemini(toxic_text):\n",
        "    prompt = f\"{prompt_prefix}Toxic: {toxic_text}\\nCounter:\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-pro')\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Gemini Error: {e}\"\n",
        "\n",
        "gpt_outputs = []\n",
        "gemini_outputs = []\n",
        "\n",
        "for text in tqdm(input_df['toxic_text']):\n",
        "    gpt_outputs.append(generate_with_gpt(text))\n",
        "    gemini_outputs.append(generate_with_gemini(text))\n",
        "\n",
        "input_df['gpt_counter_narrative'] = gpt_outputs\n",
        "input_df['gemini_counter_narrative'] = gemini_outputs\n",
        "\n",
        "input_df.to_excel(\"generated_counters_100.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import string\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "# === Step 1: Sample Hate Speech Dataset ===\n",
        "hate_speech_samples = [\n",
        "    \"All immigrants are ruining our country.\",\n",
        "    \"Women are too emotional to be leaders.\",\n",
        "    \"People from that religion are terrorists.\",\n",
        "    \"Gay people are unnatural.\",\n",
        "    \"Disabled people are a burden on society.\"\n",
        "]\n",
        "\n",
        "# === Step 2: Text Preprocessing Function ===\n",
        "def preprocess_text(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    return text.strip()\n",
        "\n",
        "# === Step 3: Dummy Counter-Narrative Generator ===\n",
        "def generate_counter_narrative(text: str) -> str:\n",
        "    templates = [\n",
        "        \"I believe in treating everyone with respect, regardless of their background.\",\n",
        "        \"We should judge people by their actions, not stereotypes.\",\n",
        "        \"Every individual deserves equal rights and opportunities.\",\n",
        "        \"Hate has no place in a compassionate society.\",\n",
        "        \"Inclusivity makes our communities stronger, not weaker.\"\n",
        "    ]\n",
        "    # Pretend the \"model\" uses text context to choose a template\n",
        "    idx = random.randint(0, len(templates) - 1)\n",
        "    return templates[idx]\n",
        "\n",
        "# === Step 4: Explainable Model Simulation ===\n",
        "def explain_model(text: str) -> str:\n",
        "    explanation = (\n",
        "        f\"Identified bias in text: '{text}'.\\n\"\n",
        "        \"Reason: Presence of stereotypical or discriminatory language.\\n\"\n",
        "        \"Suggested counter-narrative: Promote empathy, equality, and facts.\"\n",
        "    )\n",
        "    return explanation\n",
        "\n",
        "# === Step 5: Batch Processing Function ===\n",
        "def process_batch(texts: List[str]) -> List[dict]:\n",
        "    results = []\n",
        "    for i, text in enumerate(texts):\n",
        "        print(f\"Processing {i+1}/{len(texts)}: {text}\")\n",
        "        preprocessed = preprocess_text(text)\n",
        "        counter_narrative = generate_counter_narrative(preprocessed)\n",
        "        explanation = explain_model(preprocessed)\n",
        "        results.append({\n",
        "            \"original\": text,\n",
        "            \"preprocessed\": preprocessed,\n",
        "            \"counter_narrative\": counter_narrative,\n",
        "            \"explanation\": explanation\n",
        "        })\n",
        "        time.sleep(1)  # simulate model latency\n",
        "    return results\n",
        "\n",
        "# === Step 6: Display Results ===\n",
        "def display_results(results: List[dict]):\n",
        "    print(\"\\n=== Counter-Narrative Generation Results ===\\n\")\n",
        "    for result in results:\n",
        "        print(f\"Original Text: {result['original']}\")\n",
        "        print(f\"Preprocessed: {result['preprocessed']}\")\n",
        "        print(f\"Counter-Narrative: {result['counter_narrative']}\")\n",
        "        print(f\"Explanation: {result['explanation']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# === Main Driver Code ===\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading hate speech samples...\\n\")\n",
        "    processed_results = process_batch(hate_speech_samples)\n",
        "    display_results(processed_results)\n"
      ],
      "metadata": {
        "id": "D1Lmm631A1Ry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}