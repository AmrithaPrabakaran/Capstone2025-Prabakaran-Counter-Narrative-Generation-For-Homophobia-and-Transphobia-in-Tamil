{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Generating pairs in both gemini and GPT"
      ],
      "metadata": {
        "id": "5aJHDHni8-fv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJirJfkf8SpI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCcHuFOoq2ste0srbmOTcQhNCtPwM0FvdM'\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "examples_df = pd.read_excel(\"counter_narrative.xlsx\")\n",
        "input_df = pd.read_excel(\"test.xlsx\").head(100)\n",
        "\n",
        "prompt_prefix = \"\"\n",
        "for _, row in examples_df.iterrows():\n",
        "    prompt_prefix += f\"Toxic: {row['toxic_text']}\\nCounter: {row['counter_narrative']}\\n\\n\"\n",
        "\n",
        "def generate_with_gpt(toxic_text):\n",
        "    prompt = f\"{prompt_prefix}Toxic: {toxic_text}\\nCounter:\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        return f\"GPT Error: {e}\"\n",
        "\n",
        "def generate_with_gemini(toxic_text):\n",
        "    prompt = f\"{prompt_prefix}Toxic: {toxic_text}\\nCounter:\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-pro')\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Gemini Error: {e}\"\n",
        "\n",
        "gpt_outputs = []\n",
        "gemini_outputs = []\n",
        "\n",
        "for text in tqdm(input_df['toxic_text']):\n",
        "    gpt_outputs.append(generate_with_gpt(text))\n",
        "    gemini_outputs.append(generate_with_gemini(text))\n",
        "\n",
        "input_df['gpt_counter_narrative'] = gpt_outputs\n",
        "input_df['gemini_counter_narrative'] = gemini_outputs\n",
        "\n",
        "input_df.to_excel(\"generated_counters_100.xlsx\", index=False)\n"
      ]
    }
  ]
}